{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the local database\n",
    "db = sqlite3.connect(\"northstar_athletics_test.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the cursor\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22b4e4d7260>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Table\n",
    "\n",
    "#DROP TABLE IF EXISTS is used to avoid an error if we try to drop the table and it doesn't exist\n",
    "cur.execute('''DROP TABLE IF EXISTS transactions''')\n",
    "#create table \"transactions\" and define columns and datatypes\n",
    "cur.execute('''CREATE TABLE transactions (\n",
    "    date TEXT, \n",
    "    ticket_num INT,\n",
    "    emp_num INT,\n",
    "    trans_type TEXT,\n",
    "    cust TEXT, \n",
    "    sku TEXT, \n",
    "    item TEXT, \n",
    "    size TEXT, \n",
    "    quan_sold INT, \n",
    "    quan_returned INT, \n",
    "    retail_price FLOAT, \n",
    "    price FLOAT,\n",
    "    unmatched FLOAT, \n",
    "    perks FLOAT, \n",
    "    markdown FLOAT, \n",
    "    returned FLOAT, \n",
    "    net_sale FLOAT, \n",
    "    cost FLOAT, \n",
    "    gp_percent INT,\n",
    "    payment_type TEXT,\n",
    "    time TEXT\n",
    "    )''')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Transaction Rows to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to the Sales Journal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-01 173050 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-02 203137 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-03 200546 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-04 180049 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-05 171424 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-06 200133 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-07 201210 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-08 204415 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-09 200306 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-10 200726 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-11 180112 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-12 172021 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-13 200544 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-14 201012 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-15 202110 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-16 200838 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-17 200638 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-18 190257 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-19 175049 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-20 200113 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-21 200240 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-22 200318 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-23 201646 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-24 200844 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-25 184319 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-26 172525 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-27 200304 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-28 200358 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-29 204532 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-30 205800 Sales Journal .txt\n",
      "Sales Journal Jan 2020\\MAIN-RICS 2020-01-31 200158 Sales Journal .txt\n"
     ]
    }
   ],
   "source": [
    "#Set the path to the folder containing all the sales journal files \n",
    "path = \"Sales Journal Jan 2020/*.txt\"\n",
    "\n",
    "#Check to make sure it's reading all the file names\n",
    "for fname in glob.glob(path) :\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_of_new_ticket = re.compile(r'D[ ]{1,}[0-9]{3,5}')\n",
    "good_row_re = re.compile(r'D[ ]{7}[0-9]')\n",
    "date_re = re.compile(r'1?[0-9]/[0-9]{1,2}/[0-9]{4}')\n",
    "time_re = re.compile(r'[0-9]{2}:[0-9]{2} [AP][M]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to Write Transaction Rows to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in glob.glob(path) :    \n",
    "    \n",
    "    hit_start = False\n",
    "    new_ticket = False\n",
    "    have_date = False\n",
    "    \n",
    "    ## is_return \n",
    "\n",
    "    with open(fname, 'r') as ifile: \n",
    "        for row in ifile :\n",
    "\n",
    "            if not have_date and date_re.search(row) :\n",
    "                the_date = date_re.search(row).group(0)\n",
    "                the_date = datetime.datetime.strptime(the_date, \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")\n",
    "                have_date = True\n",
    "\n",
    "            if hit_start :\n",
    "                if start_of_new_ticket.search(row) and not new_ticket and \"Regular\" in row:\n",
    "                    if \"Ticket VOIDED\" not in row:\n",
    "                        new_ticket = True\n",
    "\n",
    "                        output_rows = []\n",
    "                        \n",
    "                        ticket_num = row[1:7].strip()\n",
    "                        emp_num = row[8:10]\n",
    "                        trans_type = \"Regular\"\n",
    "                        cust = row[25:100].strip()\n",
    "                        \n",
    "                elif start_of_new_ticket.search(row) and not new_ticket and \"Gift Cert\" in row:\n",
    "                    if \"Ticket VOIDED\" not in row:\n",
    "                        new_ticket = True\n",
    "\n",
    "                        output_rows = []\n",
    "\n",
    "                        ticket_num = row[1:7].strip()\n",
    "                        emp_num = row[8:10]\n",
    "                        trans_type = \"Gift Cert\"\n",
    "                        cust = row[25:100].strip()\n",
    "                     \n",
    "\n",
    "                elif new_ticket :\n",
    "                      # Get payment type\n",
    "                    if \"Totals\" in row:\n",
    "                        payment_type = row[196:211].strip()\n",
    "                        \n",
    "                        # is ticket over?    \n",
    "                    if  row.startswith(\"NP\") or \"-\"*47 in row :\n",
    "                        new_ticket = False\n",
    "\n",
    "                        # Get time\n",
    "                        if \"-\"*47 in row : \n",
    "                            the_time = time_re.search(row).group(0) \n",
    "                        else : \n",
    "                            the_time = \"\"\n",
    "\n",
    "                        # add rows to the database\n",
    "                        for o_row in output_rows:\n",
    "                            o_row.append(payment_type)\n",
    "                            o_row.append(the_time)\n",
    "                            \n",
    "                            \n",
    "                            cur.execute('''\n",
    "                            INSERT INTO transactions (date,ticket_num,emp_num,trans_type,cust,sku,item,size,quan_sold,quan_returned,\n",
    "                                      retail_price,price,unmatched,perks,markdown,returned,net_sale,cost,gp_percent,payment_type,time)\n",
    "                            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)''', o_row)\n",
    "                           \n",
    "                    else :\n",
    "                        # if not over, process row\n",
    "                        if good_row_re.search(row) and \"Ticket VOIDED\" and \"*** No Sale ***\" not in row:\n",
    "                            if \"Totals\" not in row:\n",
    "                                sku = row[13:29].strip()\n",
    "                                item = row[29:50].strip()\n",
    "                                size = row[50:62].strip()\n",
    "                                quan_sold = row[62:67].strip()\n",
    "                                quan_returned = row[67:70].strip()\n",
    "                                retail_price = row[70:79].strip()\n",
    "                                price = row[79:89].strip()\n",
    "                                unmatched = row[89:98].strip()\n",
    "                                perks = row[98:109].strip()\n",
    "                                markdown = row[109:119].strip()\n",
    "                                returned = row[119:130].strip()\n",
    "                                net_sale = row[130:141].strip()\n",
    "                                cost = row[141:149].strip()\n",
    "                                gp_percent = row[149:155].strip()\n",
    "                                payment_type = row[196:211].strip()\n",
    "                                \n",
    "                            output_rows.append([the_date,ticket_num,emp_num,trans_type,cust,sku,item,size,quan_sold,quan_returned,\n",
    "                                          retail_price,price,unmatched,perks,markdown,returned,net_sale,cost,gp_percent])\n",
    "                            # if returned != 0 \n",
    "\n",
    "\n",
    "            if \"-------- SKU --------\" in row :\n",
    "                hit_start = True\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
